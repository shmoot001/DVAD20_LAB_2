# üß© Topo

```python
class OnePodFatTree(Topo):
    def build(self):
        h1, h2, h3, h4 = [self.addHost(f'h{i}') for i in range(1, 5)]
        s1, s2, s3, s4 = [self.addSwitch(f's{i}') for i in range(1, 5)]
        opts = dict(bw=20, delay='1ms', use_htb=True)
        self.addLink(h1, s1, **opts)
        self.addLink(h2, s1, **opts)
        self.addLink(h3, s3, **opts)
        self.addLink(h4, s3, **opts)
        self.addLink(s1, s2, **opts)
        self.addLink(s1, s4, **opts)
        self.addLink(s3, s2, **opts)
        self.addLink(s3, s4, **opts)
        print("[TOPO] One-Pod FatTree built successfully")
```

---

# üß† Vad √§r det h√§r?

Den h√§r klassen definierar en **Mininet-topologi** ‚Äî allts√• den virtuella n√§tverksstruktur som ditt experiment bygger upp.
Den efterliknar en **1-pod Fat-Tree-topologi**, vilket √§r en vanlig design i datacenter.

I den h√§r miniversionen har du:

* **4 hosts** (h1‚Äìh4)
* **4 switchar** (s1‚Äìs4)
* L√§nkar mellan dem med definierad **bandbredd (bw)** och **f√∂rdr√∂jning (delay)**

---

# üîπ 1Ô∏è‚É£ Klassdefinition

```python
class OnePodFatTree(Topo):
```

* Klassen `OnePodFatTree` **√§rver fr√•n `Topo`**, som kommer fr√•n Mininet-biblioteket.
* `Topo` anv√§nds f√∂r att skapa anpassade n√§tverk med hosts, switchar och l√§nkar.
* Genom att √§rva fr√•n `Topo` kan du bygga din egen topologi genom att implementera metoden `build()`.

üß† Det betyder: n√§r du skapar `topo = OnePodFatTree()`, s√• anropas automatiskt funktionen `build()` f√∂r att bygga n√§tet.

---

# üîπ 2Ô∏è‚É£ build()-metoden

```python
def build(self):
```

Detta √§r ‚Äúritningen‚Äù f√∂r n√§tverket.
Allt som l√§ggs till h√§r (hosts, switchar, l√§nkar) kommer att finnas i Mininet-n√§tverket n√§r det startas.

---

# üîπ 3Ô∏è‚É£ Skapa hosts

```python
h1, h2, h3, h4 = [self.addHost(f'h{i}') for i in range(1, 5)]
```

* `self.addHost()` l√§gger till en host i topologin.
* Loopen `[self.addHost(f'h{i}') for i in range(1, 5)]` skapar fyra hosts med namnen `h1`, `h2`, `h3`, `h4`.
* Dessa representerar **slutanv√§ndare eller servrar** i n√§tet.

üß† I Mininet f√•r varje host:

* ett eget virtuellt n√§tverksinterface,
* en egen IP-adress (t.ex. `10.0.0.1`),
* och kan k√∂ra kommandon (t.ex. `ping`, `iperf`, etc.).

---

# üîπ 4Ô∏è‚É£ Skapa switchar

```python
s1, s2, s3, s4 = [self.addSwitch(f's{i}') for i in range(1, 5)]
```

* `self.addSwitch()` l√§gger till en OpenFlow-switch i n√§tverket.
* Du f√•r fyra switchar: `s1`, `s2`, `s3`, `s4`.
* Dessa kopplas senare ihop med l√§nkar (se nedan).
* Alla dessa switchar kommer att kopplas till din Ryu-controller n√§r n√§tet startas.

üß† DPID (datapath ID) f√∂r dessa switchar s√§tts automatiskt baserat p√• namnet:
`s1 ‚Üí DPID=1`, `s2 ‚Üí DPID=2`, osv.

---

# üîπ 5Ô∏è‚É£ Definiera l√§nkegenskaper

```python
opts = dict(bw=20, delay='1ms', use_htb=True)
```

H√§r definieras standardegenskaper f√∂r varje l√§nk:

* **bw=20** ‚Üí Bandwidth = 20 Mbps
* **delay='1ms'** ‚Üí L√§nkf√∂rdr√∂jning = 1 millisekund
* **use_htb=True** ‚Üí Anv√§nd Linux HTB (Hierarchical Token Bucket) f√∂r att kontrollera bandbredd.

üí° Detta simulerar realistiska n√§tverksf√∂rh√•llanden i datacenter (snabba men inte perfekta l√§nkar).

---

# üîπ 6Ô∏è‚É£ L√§gg till l√§nkar (hosts ‚Üî switchar)

```python
self.addLink(h1, s1, **opts)
self.addLink(h2, s1, **opts)
self.addLink(h3, s3, **opts)
self.addLink(h4, s3, **opts)
```

* Kopplar hosts till sina edge-switchar:

  * h1 och h2 kopplas till s1
  * h3 och h4 kopplas till s3

üß† Det betyder att:

* s1 fungerar som **edge-switch** f√∂r h1 och h2.
* s3 fungerar som **edge-switch** f√∂r h3 och h4.

---

# üîπ 7Ô∏è‚É£ L√§gg till l√§nkar (switchar ‚Üî aggregering)

```python
self.addLink(s1, s2, **opts)
self.addLink(s1, s4, **opts)
self.addLink(s3, s2, **opts)
self.addLink(s3, s4, **opts)
```

Detta skapar k√§rnan i din **Fat-Tree-struktur**:

* s1 och s3 (edge-switchar) kopplas upp till **s2 och s4 (aggregation-switchar)**
* Det blir **fyra l√§nkar totalt** mellan edge och aggregation.

üß† Resultatet √§r en symmetrisk struktur ‚Äî tv√• v√§gar mellan varje hostpar.
Round Robin i din Ryu-controller kommer att anv√§nda dessa uplinks (port 1 och 2) p√• s2/s4 f√∂r att f√∂rdela trafiken.

---

# üîπ 8Ô∏è‚É£ Utskrift (f√∂r loggning)

```python
print("[TOPO] One-Pod FatTree built successfully")
```

* Skriver ut ett bekr√§ftelsemeddelande i terminalen n√§r topologin skapats.
* Hj√§lper dig att se att n√§tverket byggts utan fel.

---

# üîπ 9Ô∏è‚É£ Resultat: topologin (visuellt)

```
          s2           s4
         /  \         /  \
       s1----\-------/----s3
      /  \             /  \
    h1   h2          h3   h4
```

* s1 & s3 = edge-switchar (kopplade till hosts)
* s2 & s4 = aggregation-switchar (kopplade till edges via uplinks)
* Round Robin-logiken balanserar trafiken mellan v√§gar via s2 och s4.

---

# üîπ Sammanfattning i punktform

| Del             | Vad den g√∂r                                               |
| --------------- | --------------------------------------------------------- |
| **addHost()**   | Skapar hosts (h1‚Äìh4).                                     |
| **addSwitch()** | Skapar switchar (s1‚Äìs4).                                  |
| **opts**        | Definierar l√§nkegenskaper (bandbredd, delay).             |
| **addLink()**   | Kopplar ihop hosts och switchar enligt Fat-Tree-struktur. |
| **print()**     | Bekr√§ftar att topologin √§r byggd.                         |

---

# üí° Kortfattat

> `OnePodFatTree` skapar en liten men realistisk datacenter-topologi med fyra switchar och fyra hosts.
> s1 och s3 fungerar som edge-switchar, s2 och s4 som aggregation-switchar.
> Trafik fr√•n hosts skickas upp√•t till aggregation-niv√•n, d√§r din Ryu-controller anv√§nder **Round Robin** f√∂r att j√§mnt f√∂rdela trafiken mellan de tv√• uplinks.




# üß© ECDFc

```python
# -------------------------------
# ECDF distributions
# -------------------------------
WEBSEARCH_ECDF = [(10_000,0.10),(20_000,0.30),(35_000,0.60),
                  (50_000,0.90),(80_000,0.95),(100_000,1.0)]
DATAMINING_ECDF = [
    (50_000,      0.10),  # 50 KB    ‚Üí 10% of flows are ‚â§ 50 KB
    (100_000,     0.20),  # 100 KB   ‚Üí 20% of flows are ‚â§ 100 KB
    (250_000,     0.30),  # 250 KB   ‚Üí 30% of flows are ‚â§ 250 KB
    (500_000,     0.40),  # 500 KB   ‚Üí 40% of flows are ‚â§ 500 KB
    (1_000_000,   0.60),  # 1 MB     ‚Üí 60% of flows are ‚â§ 1 MB
    (2_000_000,   0.70),  # 2 MB     ‚Üí 70% of flows are ‚â§ 2 MB
    (5_000_000,   0.80),  # 5 MB     ‚Üí 80% of flows are ‚â§ 5 MB
    (10_000_000,  1.00),  # 10 MB    ‚Üí 100% of flows are ‚â§ 10 MB (max)
]

def sample_from_ecdf(ecdf):
    r = random.random()
    for v, p in ecdf:
        if r <= p:
            return v
    return ecdf[-1][0]

def get_sampler(t):
    return (lambda: sample_from_ecdf(WEBSEARCH_ECDF)) if t==1 else (lambda: sample_from_ecdf(DATAMINING_ECDF))
```

---

# üß† Vad betyder det h√§r?

H√§r definieras tv√• **empiriska f√∂rdelningar (eCDFs)** ‚Äî en f√∂r WebSearch och en f√∂r DataMining.
De anv√§nds f√∂r att **simulera olika typer av n√§tverkstrafik** med realistiska variationer i fl√∂desstorlek (dvs. hur mycket data som skickas per ‚Äúflow‚Äù).

üí° eCDF = *empirical cumulative distribution function*
Det betyder: ‚Äúf√∂r varje fl√∂desstorlek, hur stor andel (%) av alla fl√∂den √§r mindre √§n eller lika stora som detta v√§rde?‚Äù

---

# üîπ 1Ô∏è‚É£ WEBSEARCH_ECDF

```python
WEBSEARCH_ECDF = [
    (10_000, 0.10),
    (20_000, 0.30),
    (35_000, 0.60),
    (50_000, 0.90),
    (80_000, 0.95),
    (100_000, 1.0)
]
```

* Denna lista representerar WebSearch-trafik, som typiskt best√•r av **m√•nga sm√• fl√∂den** (t.ex. webbfr√•gor, API-anrop).
* Formatet √§r `(storlek_i_bytes, sannolikhet)`.

| Flow Size (bytes) | Cumulative Probability | F√∂rklaring                              |
| ----------------- | ---------------------- | --------------------------------------- |
| 10 000            | 0.10                   | 10% av alla WebSearch-fl√∂den √§r ‚â§ 10 KB |
| 20 000            | 0.30                   | 30% √§r ‚â§ 20 KB                          |
| 35 000            | 0.60                   | 60% √§r ‚â§ 35 KB                          |
| 50 000            | 0.90                   | 90% √§r ‚â§ 50 KB                          |
| 80 000            | 0.95                   | 95% √§r ‚â§ 80 KB                          |
| 100 000           | 1.00                   | 100% √§r ‚â§ 100 KB (ingen st√∂rre)         |

üí° **Tolkning:** WebSearch-trafik √§r l√§tt och snabb ‚Äî de flesta fl√∂den √§r sm√•, vilket ger korta FCT (Flow Completion Times).

---

# üîπ 2Ô∏è‚É£ DATAMINING_ECDF

```python
DATAMINING_ECDF = [
    (50_000, 0.10),
    (100_000, 0.20),
    (250_000, 0.30),
    (500_000, 0.40),
    (1_000_000, 0.60),
    (2_000_000, 0.70),
    (5_000_000, 0.80),
    (10_000_000, 1.00)
]
```

* Representerar **tyngre datacenter-trafik**, som t.ex. fil√∂verf√∂ringar, databasreplikering eller analysjobb.
* H√§r √§r fl√∂dena mycket st√∂rre (upp till 10 MB).

| Flow Size  | Cumulative Probability | F√∂rklaring             |
| ---------- | ---------------------- | ---------------------- |
| 50 000     | 0.10                   | 10% av fl√∂dena ‚â§ 50 KB |
| 500 000    | 0.40                   | 40% ‚â§ 500 KB           |
| 1 000 000  | 0.60                   | 60% ‚â§ 1 MB             |
| 10 000 000 | 1.00                   | 100% ‚â§ 10 MB           |

üí° **Tolkning:** DataMining-fl√∂den √§r l√§ngre och mer bandbreddskr√§vande. De belastar n√§tet mer och leder ofta till h√∂gre FCT.

---

# üîπ 3Ô∏è‚É£ sample_from_ecdf(ecdf)

```python
def sample_from_ecdf(ecdf):
    r = random.random()
    for v, p in ecdf:
        if r <= p:
            return v
    return ecdf[-1][0]
```

### üîç F√∂rklaring:

1. `r = random.random()` ‚Üí genererar ett slumpm√§ssigt tal mellan 0 och 1.
   Exempel: `r = 0.37`

2. `for v, p in ecdf:` ‚Üí loopar igenom alla `(storlek, sannolikhet)` i eCDF-listan.

3. `if r <= p:` ‚Üí hittar f√∂rsta punkten d√§r sannolikheten i eCDF √§r st√∂rre √§n `r`.
   ‚Üí returnerar den fl√∂desstorleken `v`.

4. Om inget matchar (r ~ 1.0) ‚Üí returnerar sista v√§rdet (det st√∂rsta).

üß† Det h√§r motsvarar att **dra ett slumpm√§ssigt prov fr√•n distributionen**.
‚Üí Varje g√•ng funktionen kallas returnerar den en **ny slumpm√§ssig fl√∂desstorlek** enligt sannolikheterna i eCDF.

---

# üîπ 4Ô∏è‚É£ get_sampler(t)

```python
def get_sampler(t):
    return (lambda: sample_from_ecdf(WEBSEARCH_ECDF)) if t==1 else (lambda: sample_from_ecdf(DATAMINING_ECDF))
```

### üîç F√∂rklaring:

* `t` √§r en parameter som anger **vilken typ av trafik** vi vill simulera:

  * `t = 1` ‚Üí WebSearch
  * `t = 2` ‚Üí DataMining

Funktionen returnerar en **lambda (anonym funktion)** som du kan anropa f√∂r att f√• ett nytt fl√∂desprov varje g√•ng.

üß† Exempel:

```python
sampler = get_sampler(2)   # 2 = DataMining
flow_size = sampler()      # Returnerar t.ex. 1_000_000 bytes (‚âà 1 MB)
```

Detta g√∂r koden enkel att anv√§nda i trafikgeneratorn senare:

```python
size_b = size_sampler()  # varje g√•ng: ny slumpm√§ssig storlek
```

---

# üîπ 5Ô∏è‚É£ Varf√∂r beh√∂vs detta?

Syftet √§r att simulera **verklig datacentertrafik**.
Alla fl√∂den √§r inte lika stora ‚Äî vissa √§r sm√• (snabba API-anrop), andra √§r j√§ttestora (dataanalys).

Att anv√§nda eCDF g√∂r att simuleringen blir:

* **realistisk** (efterliknar verkliga m√§tdata),
* **replicerbar** (du kan √•teranv√§nda samma f√∂rdelning i olika experiment),
* **kontrollerbar** (du kan j√§mf√∂ra olika workload-typer under samma villkor).

---

# üîπ 6Ô∏è‚É£ Sammanfattning

| Del                  | Vad den g√∂r                                                                        |
| -------------------- | ---------------------------------------------------------------------------------- |
| `WEBSEARCH_ECDF`     | Beskriver sannolik f√∂rdelning av sm√• fl√∂den (typiska webbtj√§nster).                |
| `DATAMINING_ECDF`    | Beskriver sannolik f√∂rdelning av stora fl√∂den (tunga datajobb).                    |
| `sample_from_ecdf()` | Returnerar en slumpm√§ssig fl√∂desstorlek baserat p√• eCDF.                           |
| `get_sampler(t)`     | V√§ljer r√§tt eCDF (WebSearch eller DataMining) och returnerar en generatorfunktion. |

---

# üí° Kortfattat

> Den h√§r delen av koden definierar hur **fl√∂desstorlekarna slumpas fram** i simuleringen.
> Den anv√§nder empiriska CDF-f√∂rdelningar f√∂r tv√• trafiktyper:
> **WebSearch** med sm√• snabba fl√∂den, och **DataMining** med st√∂rre, bandbreddskr√§vande fl√∂den.
>
> Genom att dra slumpm√§ssiga prover fr√•n dessa distributioner f√•r varje simulering en realistisk blandning av sm√• och stora fl√∂den ‚Äî precis som i ett verkligt datacenter.



# üß© genDCTraffic

```python
def genDCTraffic(src, dst, traffic_type, intensity, duration, port=5001, on_done=None):
    sampler = get_sampler(traffic_type)
    recv = dst.popen(f"iperf -s -p {port} > /dev/null 2>&1", shell=True)
    time.sleep(0.3)
    in_flight, meta, seq, fcts = {}, {}, 0, []
    t0, next_tick = time.time(), time.time()

    try:
        while (time.time() - t0) < duration or in_flight:
            now = time.time()
            # Launch new flows per second
            if now >= next_tick and (now - t0) < duration:
                for _ in range(intensity):
                    seq += 1
                    size_b = sampler()
                    start = time.time()
                    cmd = f"iperf -c {dst.IP()} -p {port} -n {size_b} > /dev/null 2>&1"
                    proc = src.popen(cmd, shell=True)
                    in_flight[seq] = proc
                    meta[seq] = {"start": start, "size": size_b}
                next_tick += 1
            # Check completions
            for fid, proc in list(in_flight.items()):
                if proc.poll() is not None:
                    end = time.time()
                    fct = end - meta[fid]["start"]
                    fcts.append(fct)
                    record = {"src": src.name, "dst": dst.name,
                              "traffic_type": traffic_type,
                              "intensity": intensity,
                              "size_bytes": meta[fid]["size"],
                              "fct_s": fct}
                    if on_done:
                        on_done(record)
                    del in_flight[fid], meta[fid]
            time.sleep(0.01)
    finally:
        recv.terminate()
    return fcts
```

---

# üß† Vad funktionen g√∂r

Den h√§r funktionen **skapar och m√§ter trafik mellan tv√• Mininet-hostar (`src` och `dst`)**.
Den anv√§nder verktyget **iperf** f√∂r att simulera TCP-fl√∂den och m√§ter **hur l√•ng tid (Flow Completion Time, FCT)** varje fl√∂de tar att avslutas.

Den imiterar allts√• realistisk datacentertrafik med flera samtidiga sm√• eller stora fl√∂den, beroende p√•:

* `traffic_type` (WebSearch eller DataMining),
* `intensity` (antal fl√∂den per sekund),
* `duration` (hur l√§nge trafiken ska genereras).

---

# üîπ 1Ô∏è‚É£ Funktionens parametrar

| Parameter      | Typ          | F√∂rklaring                                                         |
| -------------- | ------------ | ------------------------------------------------------------------ |
| `src`          | Mininet host | K√§lla (t.ex. h1) som skickar trafiken                              |
| `dst`          | Mininet host | Destination (t.ex. h4) som tar emot trafiken                       |
| `traffic_type` | int          | 1 = WebSearch, 2 = DataMining                                      |
| `intensity`    | int          | Antal nya fl√∂den som startas varje sekund                          |
| `duration`     | int          | Hur l√§nge nya fl√∂den genereras (sekunder)                          |
| `port`         | int          | TCP-port som iperf anv√§nder (standard 5001)                        |
| `on_done`      | funktion     | Callback som k√∂rs n√§r ett fl√∂de avslutas (t.ex. loggning till fil) |

---

# üîπ 2Ô∏è‚É£ V√§lj r√§tt trafiksampler

```python
sampler = get_sampler(traffic_type)
```

* H√§mtar r√§tt **eCDF-sampler** baserat p√• `traffic_type`.
* Det betyder att varje g√•ng vi kallar `sampler()`, f√•r vi **en slumpm√§ssig flow size** enligt WebSearch- eller DataMining-f√∂rdelningen.

üß† Exempel:

```python
size_b = sampler()   # returnerar t.ex. 50_000 bytes f√∂r WebSearch
```

---

# üîπ 3Ô∏è‚É£ Starta iperf-server p√• destinationen

```python
recv = dst.popen(f"iperf -s -p {port} > /dev/null 2>&1", shell=True)
time.sleep(0.3)
```

* Startar en **iperf-server** (`-s`) p√• mottagaren (`dst`).
* `> /dev/null 2>&1` tystar utmatningen (du kan ta bort det f√∂r debugging).
* `time.sleep(0.3)` ger servern en liten stund att starta upp innan klienter ansluter.

üß† I datacentermodell:

> `dst` agerar som **server** som tar emot data fr√•n flera **klientfl√∂den** (`src`).

---

# üîπ 4Ô∏è‚É£ Initiera variabler

```python
in_flight, meta, seq, fcts = {}, {}, 0, []
t0, next_tick = time.time(), time.time()
```

* `in_flight`: dict med aktiva fl√∂den (`flow_id ‚Üí process`).
* `meta`: lagrar starttid och storlek per flow.
* `seq`: r√§knare f√∂r att ge varje flow ett unikt ID.
* `fcts`: lista d√§r alla **Flow Completion Times** sparas.
* `t0`: starttid f√∂r hela experimentet.
* `next_tick`: tidpunkt d√• n√§sta ‚Äúbatch‚Äù av fl√∂den ska startas (1 sekund mellan varje).

---

# üîπ 5Ô∏è‚É£ Huvudloopen ‚Äì skapa och m√§ta trafik

```python
while (time.time() - t0) < duration or in_flight:
```

Den h√§r loopen k√∂rs s√• l√§nge experimentet p√•g√•r (och tills alla fl√∂den √§r klara).
Tv√• saker h√§nder inuti:

---

## üß© a) Starta nya fl√∂den varje sekund

```python
if now >= next_tick and (now - t0) < duration:
    for _ in range(intensity):
        seq += 1
        size_b = sampler()
        start = time.time()
        cmd = f"iperf -c {dst.IP()} -p {port} -n {size_b} > /dev/null 2>&1"
        proc = src.popen(cmd, shell=True)
        in_flight[seq] = proc
        meta[seq] = {"start": start, "size": size_b}
    next_tick += 1
```

### üîç Vad som h√§nder:

* Varje sekund (`now >= next_tick`) startas `intensity` antal nya fl√∂den.
* Varje fl√∂de:

  1. F√•r ett unikt ID (`seq`).
  2. Slumpas fram en storlek (`size_b`) via eCDF.
  3. Startar en iperf-klient p√• `src` som skickar data till `dst`.
  4. Lagrar starttid och storlek i `meta`.

üß† Exempel:
Om `intensity=4` och `duration=10`, startas 4 nya fl√∂den varje sekund under 10 sekunder ‚Üí totalt 40 fl√∂den.

---

## üß© b) Kolla om fl√∂den √§r f√§rdiga

```python
for fid, proc in list(in_flight.items()):
    if proc.poll() is not None:
        end = time.time()
        fct = end - meta[fid]["start"]
        fcts.append(fct)
        record = {"src": src.name, "dst": dst.name,
                  "traffic_type": traffic_type,
                  "intensity": intensity,
                  "size_bytes": meta[fid]["size"],
                  "fct_s": fct}
        if on_done:
            on_done(record)
        del in_flight[fid], meta[fid]
```

### üîç Vad som h√§nder:

* `proc.poll()` returnerar `None` om processen fortfarande k√∂rs, annars betyder det att fl√∂det √§r klart.
* Ber√§kna **Flow Completion Time (FCT)**:

  ```python
  fct = end - start
  ```
* Spara resultatet i `fcts`.
* Om `on_done` (callback) √§r satt ‚Üí skicka en loggrad med alla metadata (kallas i `ExperimentHandler`).
* Ta bort fl√∂det fr√•n `in_flight` (det √§r nu avslutat).

üí° FCT √§r den centrala m√§tningen i experimentet ‚Äî den visar **hur snabbt fl√∂den avslutas** under olika belastningsniv√•er.

---

# üîπ 6Ô∏è‚É£ V√§nta en liten stund mellan iterationerna

```python
time.sleep(0.01)
```

F√∂rhindrar att loopen k√∂rs f√∂r snabbt (CPU-sn√•lt).

---

# üîπ 7Ô∏è‚É£ St√§ng iperf-servern

```python
finally:
    recv.terminate()
```

N√§r alla fl√∂den √§r f√§rdiga avslutas iperf-servern p√• mottagarsidan.

---

# üîπ 8Ô∏è‚É£ Returnera alla FCT-v√§rden

```python
return fcts
```

Funktionen returnerar en lista med alla flow completion times i sekunder.
Dessa anv√§nds sedan f√∂r statistik och plottning.

---

# üîπ 9Ô∏è‚É£ Sammanfattning i punktform

| Del             | Vad den g√∂r                                   |
| --------------- | --------------------------------------------- |
| `get_sampler()` | H√§mtar trafiksamplare (WebSearch/DataMining)  |
| `iperf -s`      | Startar server p√• mottagaren                  |
| `iperf -c`      | Startar klientfl√∂den fr√•n s√§ndaren            |
| `intensity`     | Antal nya fl√∂den per sekund                   |
| `duration`      | Hur l√§nge nya fl√∂den startas                  |
| `FCT`           | Flow Completion Time, m√§ts f√∂r varje fl√∂de    |
| `on_done`       | Callback som loggar varje fl√∂de i JSON-format |
| `return fcts`   | Returnerar lista av alla FCT:er f√∂r analys    |

---

# üí° Kortfattat

> `genDCTraffic()` simulerar realistisk datacentertrafik mellan tv√• v√§rdar med olika intensitet och fl√∂desstorlek.
> Den startar flera iperf-fl√∂den, m√§ter deras avslutningstider (FCT), och loggar resultaten.
>
> WebSearch-trafik best√•r mest av sm√•, snabba fl√∂den ‚Äî DataMining best√•r av st√∂rre, l√•ngsammare fl√∂den.
>
> Resultaten anv√§nds f√∂r att analysera hur n√§tverkets prestanda p√•verkas av belastning och trafiktyp.



# üß© Experiment

```python
class Experiment:
    def __init__(self, net):
        self.net = net
        self.logger = FlowLogger()

    def _on_done(self, rec):
        print(f"[Flow] {rec}")
        self.logger.write(rec)

    def run(self, times=10, intensity=10, duration=10):
        hosts = [self.net.get(f"h{i}") for i in range(1, 5)]
        for rep in range(times):
            src, dst = random.sample(hosts, 2)
            print(f"\n[Run {rep+1}/{times}] {src.name} ‚Üí {dst.name}")
            for t in (1, 2):
                label = "WebSearch" if t==1 else "DataMining"
                print(f"  Type={label}")
                for bulk in range(1, intensity+1):
                    print(f"    Intensity {bulk}/{intensity}")
                    genDCTraffic(src, dst, t, bulk, duration, on_done=self._on_done)
```

---

# üß† Vad klassen g√∂r

Klassen `Experiment` √§r **en teststyrning (experiment runner)** som automatiserar trafikexperimentet i ditt datacenter-n√§tverk.

Den:

1. H√§mtar alla Mininet-hosts (`h1‚Äìh4`),
2. Slumpar vilka tv√• som kommunicerar (k√§lla och destination),
3. K√∂r trafik f√∂r b√•da trafiktyperna (WebSearch och DataMining),
4. √ñkar trafikintensiteten stegvis (1 ‚Üí 10 fl√∂den/s),
5. Loggar alla Flow Completion Times (FCT) med hj√§lp av `FlowLogger`.

---

# üîπ 1Ô∏è‚É£ Konstruktor (`__init__`)

```python
def __init__(self, net):
    self.net = net
    self.logger = FlowLogger()
```

### üîç F√∂rklaring

* `net`: √§r en Mininet-instans som redan skapats (med topologin `OnePodFatTree`).
* `self.net`: sparar referensen s√• att experimentet kan h√§mta hosts.
* `self.logger = FlowLogger()` skapar en logger som skriver varje avslutat fl√∂de till en fil, vanligtvis `flows.jsonl`.

üí° **T√§nk p√• detta som:**

> ‚ÄúExperimentet beh√∂ver veta vilka hosts som finns i n√§tet och ha n√•gon som skriver ner resultaten.‚Äù

---

# üîπ 2Ô∏è‚É£ Callback-funktion f√∂r f√§rdiga fl√∂den (`_on_done`)

```python
def _on_done(self, rec):
    print(f"[Flow] {rec}")
    self.logger.write(rec)
```

### üîç Vad den g√∂r:

* Denna funktion kallas automatiskt varje g√•ng ett fl√∂de avslutas (fr√•n `genDCTraffic()` via `on_done`).
* `rec` √§r en dictionary med information om fl√∂det:

  ```python
  {"src": "h1", "dst": "h4", "traffic_type": 1,
   "intensity": 3, "size_bytes": 50000, "fct_s": 0.12}
  ```
* Skriver ut en loggrad i terminalen.
* Skickar posten vidare till `FlowLogger` f√∂r att sparas i fil.

üß† Det betyder:

> Varje g√•ng ett fl√∂de slutar, visas det direkt p√• sk√§rmen och loggas i en datafil.

---

# üîπ 3Ô∏è‚É£ K√∂r experimentet (`run()`)

```python
def run(self, times=10, intensity=10, duration=10):
```

### üîç Parametrar:

| Parameter   | Betydelse                                                |
| ----------- | -------------------------------------------------------- |
| `times`     | Hur m√•nga experimentomg√•ngar (repetitioner) ska k√∂ras    |
| `intensity` | Max antal fl√∂den per sekund (√∂kar stegvis fr√•n 1 till N) |
| `duration`  | Hur l√§nge varje intensitet k√∂rs (sekunder)               |

üí° Exempel:
`run(times=10, intensity=10, duration=10)` betyder att du:

* K√∂r 10 omg√•ngar,
* Varje g√•ng √∂kar fl√∂desintensiteten fr√•n 1 till 10 flows/s,
* Varje niv√• p√•g√•r i 10 sekunder.

---

# üîπ 4Ô∏è‚É£ H√§mta hosts fr√•n Mininet

```python
hosts = [self.net.get(f"h{i}") for i in range(1, 5)]
```

* H√§mtar alla hosts (`h1`, `h2`, `h3`, `h4`) fr√•n n√§tverket.
* `self.net.get()` √§r en Mininet-funktion f√∂r att h√§mta noder baserat p√• namn.

---

# üîπ 5Ô∏è‚É£ Upprepa experimentet flera g√•nger

```python
for rep in range(times):
    src, dst = random.sample(hosts, 2)
    print(f"\n[Run {rep+1}/{times}] {src.name} ‚Üí {dst.name}")
```

* K√∂r `times` upprepningar.
* V√§ljer slumpm√§ssigt **tv√• olika hosts** f√∂r varje k√∂rning ‚Äî en som s√§ndare (`src`), en som mottagare (`dst`).
* Skrivs ut i terminalen, t.ex.:

  ```
  [Run 3/10] h2 ‚Üí h4
  ```

üí° Det h√§r simulerar trafik mellan olika servrar i datacentret.

---

# üîπ 6Ô∏è‚É£ K√∂r b√•da trafiktyperna

```python
for t in (1, 2):
    label = "WebSearch" if t==1 else "DataMining"
    print(f"  Type={label}")
```

* Loopar √∂ver tv√• trafiktyper:

  * `1` = WebSearch
  * `2` = DataMining
* Skrivs ut i terminalen:

  ```
  Type=WebSearch
  Type=DataMining
  ```

üß† P√• s√• s√§tt k√∂r du **tv√• olika trafikprofiler** under samma experiment.

---

# üîπ 7Ô∏è‚É£ √ñka trafikintensiteten steg f√∂r steg

```python
for bulk in range(1, intensity+1):
    print(f"    Intensity {bulk}/{intensity}")
    genDCTraffic(src, dst, t, bulk, duration, on_done=self._on_done)
```

### üîç Vad som h√§nder:

* K√∂r experimentet med √∂kande intensitet: 1, 2, 3, ... upp till `intensity`.
* Varje g√•ng:

  * `bulk` anger hur m√•nga fl√∂den per sekund som startas.
  * `duration` hur l√§nge det p√•g√•r (sekunder).
  * `genDCTraffic()` startar trafiken och loggar resultaten.
* Callback `on_done=self._on_done` g√∂r att varje f√§rdigt fl√∂de skrivs till loggfilen.

Exempel i terminalen:

```
[Run 1/10] h2 ‚Üí h4
  Type=WebSearch
    Intensity 1/10
    Intensity 2/10
  Type=DataMining
    Intensity 1/10
    Intensity 2/10
```

---

# üîπ 8Ô∏è‚É£ Hur experimentet g√•r till (√∂versikt)

F√∂r varje iteration (`Run`):

1. V√§lj slumpm√§ssigt vilka hosts som kommunicerar.
2. K√∂r f√∂rst WebSearch, sedan DataMining.
3. √ñka intensiteten stegvis.
4. F√∂r varje fl√∂de: m√§t och logga FCT.
5. N√§r alla fl√∂den √§r klara ‚Üí g√• vidare till n√§sta repetition.

---

# üîπ 9Ô∏è‚É£ Sammanfattning i punktform

| Steg | Vad som h√§nder                              |
| ---- | ------------------------------------------- |
| 1    | H√§mta hosts fr√•n Mininet                    |
| 2    | Slumpa s√§ndare/mottagare                    |
| 3    | K√∂r b√•da trafiktyper (WebSearch/DataMining) |
| 4    | √ñka intensiteten (1 ‚Üí N flows/s)            |
| 5    | Starta iperf-fl√∂den med `genDCTraffic()`    |
| 6    | Logga varje fl√∂de via `_on_done()`          |
| 7    | Repetera experimentet flera g√•nger          |

---

# üí° Kortfattat

> Klassen `Experiment` styr hela experimentk√∂rningen.
> Den v√§ljer slumpm√§ssigt tv√• hosts, k√∂r b√•de WebSearch- och DataMining-trafik,
> √∂kar belastningen stegvis, och loggar resultat (Flow Completion Time, FCT)
> f√∂r varje fl√∂de via `FlowLogger`.

P√• s√• s√§tt kan du:

* j√§mf√∂ra prestanda mellan trafiktyper,
* se hur FCT f√∂r√§ndras med √∂kad intensitet,
* analysera effekten av Round Robin Load Balancing i din Ryu-controller.

---
